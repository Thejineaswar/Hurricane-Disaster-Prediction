{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport glob","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-28T17:46:55.337854Z","iopub.execute_input":"2022-03-28T17:46:55.338203Z","iopub.status.idle":"2022-03-28T17:46:55.361724Z","shell.execute_reply.started":"2022-03-28T17:46:55.338122Z","shell.execute_reply":"2022-03-28T17:46:55.361051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_dict = {}","metadata":{"execution":{"iopub.status.busy":"2022-03-28T17:46:55.719904Z","iopub.execute_input":"2022-03-28T17:46:55.72039Z","iopub.status.idle":"2022-03-28T17:46:55.724267Z","shell.execute_reply.started":"2022-03-28T17:46:55.720356Z","shell.execute_reply":"2022-03-28T17:46:55.723307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os import walk\nfor (dirpath,dir_names,filenames) in walk('../input/satellite-images-of-hurricane-damage'):\n    temp = []\n    for i in filenames:\n        temp.append(dirpath + '/' + i)\n    if(len(temp) >0):\n        path_dict[dirpath ] = temp","metadata":{"execution":{"iopub.status.busy":"2022-03-28T17:46:56.155526Z","iopub.execute_input":"2022-03-28T17:46:56.156356Z","iopub.status.idle":"2022-03-28T17:47:24.54944Z","shell.execute_reply.started":"2022-03-28T17:46:56.156309Z","shell.execute_reply":"2022-03-28T17:47:24.548679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport cv2\nfrom tqdm import tqdm \nimport glob\nimport sys\n\nimport torch \nimport torch.nn as nn \nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport pytorch_lightning as pl\nimport torchmetrics\nfrom pytorch_lightning import loggers as pl_loggers\n\n! pip install timm\nimport timm","metadata":{"execution":{"iopub.status.busy":"2022-03-28T17:47:24.552256Z","iopub.execute_input":"2022-03-28T17:47:24.552681Z","iopub.status.idle":"2022-03-28T17:47:39.267632Z","shell.execute_reply.started":"2022-03-28T17:47:24.552644Z","shell.execute_reply":"2022-03-28T17:47:39.266901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Hurricane_Data(Dataset):\n    def __init__(self,path_array : list):\n        self.path_array = path_array \n        self.compose = A.Compose([\n            A.Normalize(\n                    mean=[0.485, 0.456, 0.406],\n                    std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2()\n        ])\n    \n    def __len__(self):\n        return len(self.path_array)\n    \n    def __getitem__(self,index):\n        filename = self.path_array[index]\n        image = cv2.imread(filename)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = self.compose(image = image)['image']\n#         image = image.view(128,128,3)\n        if 'no_damage' in filename:\n            label = [0]\n        else:\n            label = [1]\n        \n        return torch.tensor(image),torch.tensor(label)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T17:51:28.137588Z","iopub.execute_input":"2022-03-28T17:51:28.137887Z","iopub.status.idle":"2022-03-28T17:51:28.148783Z","shell.execute_reply.started":"2022-03-28T17:51:28.137851Z","shell.execute_reply":"2022-03-28T17:51:28.147895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_damage = '../input/satellite-images-of-hurricane-damage/train_another/damage'\ntrain_no_damage = '../input/satellite-images-of-hurricane-damage/train_another/no_damage'\ntrain_paths = path_dict[train_damage] + path_dict[train_no_damage]\n\ntrain_damage = '../input/satellite-images-of-hurricane-damage/validation_another/damage'\ntrain_no_damage = '../input/satellite-images-of-hurricane-damage/validation_another/no_damage'\nvalid_paths = path_dict[train_damage] + path_dict[train_no_damage]\n\ntrain_damage = '../input/satellite-images-of-hurricane-damage/test_another/damage'\ntrain_no_damage = '../input/satellite-images-of-hurricane-damage/test_another/no_damage'\ntest_paths = path_dict[train_damage] + path_dict[train_no_damage]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-28T17:47:39.280271Z","iopub.execute_input":"2022-03-28T17:47:39.280653Z","iopub.status.idle":"2022-03-28T17:47:39.290137Z","shell.execute_reply.started":"2022-03-28T17:47:39.280613Z","shell.execute_reply":"2022-03-28T17:47:39.289435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LitHurricane(pl.LightningModule):\n    def __init__(self,train_paths : str ,valid_paths : str,test_paths : str):\n        super(LitHurricane,self).__init__()\n        \n        self.train_dataset = Hurricane_Data(train_paths)\n        self.valid_dataset = Hurricane_Data(valid_paths)\n        self.test_dataset = Hurricane_Data(test_paths)\n        \n        self.model = timm.create_model('resnet34', \n                                       num_classes=1,\n                                       pretrained = True\n                                      )\n        \n        self.train_loss = nn.BCEWithLogitsLoss()\n        self.valid_loss = nn.BCEWithLogitsLoss()\n        \n        self.train_acc = torchmetrics.Accuracy()\n        self.valid_acc = torchmetrics.Accuracy()\n        \n        \n        self.lr = 0.001\n        \n    def forward(self,batch):\n        return self.model(batch)\n    \n    def configure_optimizers(self):\n        return torch.optim.Adam(self.model.parameters(), lr=1e-4, weight_decay=3e-6)\n    \n    def train_dataloader(self):\n        train_loader = DataLoader(self.train_dataset,\n                             batch_size =  32,\n                             shuffle = False,\n                             sampler = None, \n                                 num_workers = os.cpu_count()\n                                 )\n\n        return train_loader\n    \n    def val_dataloader(self):\n        val_loader = DataLoader(self.valid_dataset,\n                               batch_size = 32,\n                               shuffle = False,\n                               num_workers = os.cpu_count()\n                               )\n        return val_loader\n\n    def training_step(self,batch,batch_idx):\n        image,labels = batch\n        logits = self(image)\n        loss = self.train_loss(logits,labels.type_as(logits))\n        logits = logits > 0.5\n        accuracy = self.train_acc(logits,labels.type_as(logits))\n        \n        self.log(\"train_loss_batch\", loss,prog_bar = True)\n        self.log(\"train_acc_batch\", accuracy,prog_bar = True)\n        \n        return {\n            'loss' : loss,\n            'y_pred' : logits,\n            'y_true' : labels\n        }\n    \n    \n    def training_epoch_end(self,outputs):\n        accuracy = self.train_acc.compute()\n        self.log(\"train_acc_end\",accuracy,prog_bar = True)\n        print(f\"Train accuracy for epoch {accuracy}\")\n\n    def validation_step(self,batch,batch_idx):\n        image,labels = batch\n        logits = self.model(image)\n        loss = self.valid_loss(logits,labels.float())\n        \n        logits = (logits > 0.5).int()\n        accuracy = self.valid_acc(logits,labels)\n        \n        self.log(\"valid_loss_batch\", loss,prog_bar = True)\n        self.log(\"valid_acc_batch\", accuracy,prog_bar = True)\n        \n        return {\n            'loss' : loss,\n            'y_pred' : logits,\n            'y_true' : labels\n        }\n        \n    \n    def validation_epoch_end(self,outputs):\n        accuracy = self.valid_acc.compute()\n        self.log(\"valid_acc_end\",accuracy,prog_bar = True)\n        print(f\"Valid accuracy for epoch {accuracy}\")\n        return {\n            'val_loss' : outputs[0]['loss'],\n            'val_acc_end' : accuracy\n        }","metadata":{"execution":{"iopub.status.busy":"2022-03-28T18:22:28.181106Z","iopub.execute_input":"2022-03-28T18:22:28.181377Z","iopub.status.idle":"2022-03-28T18:22:28.199056Z","shell.execute_reply.started":"2022-03-28T18:22:28.181348Z","shell.execute_reply":"2022-03-28T18:22:28.198327Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"from pytorch_lightning.callbacks.progress import ProgressBar\n\nclass LitProgressBar(ProgressBar):\n    def init_train_tqdm(self):\n        bar = super().init_train_tqdm()\n        bar.leave = True\n        return bar\n        \n    def init_validation_tqdm(self):\n        bar = super().init_validation_tqdm()\n        bar.set_description('Valid')\n        return bar\n\n        \n    def training_epoch_end(self, outputs):\n        self.trainer.progress_bar_callback.main_progress_bar.write(\n            f\"Epoch {self.trainer.current_epoch + 1} training loss={self.trainer.progress_bar_dict['train_loss']}\" +\n            f\"Accuracy={self.trainer.progress_bar_dict['train_acc_end']}\"\n        )\n\n    def validation_epoch_end(self, outputs):\n        loss = torch.stack(outputs).mean()\n        self.trainer.progress_bar_callback.main_progress_bar.write(\n            f\"Epoch {self.trainer.current_epoch + 1} validation loss={self.trainer.progress_bar_dict['val_loss']}\" +\n            f\"Valid Accuracy = {self.trainer.progress_bar_dict['valid_acc_end']}\"\n        )","metadata":{"execution":{"iopub.status.busy":"2022-03-28T17:47:39.313Z","iopub.execute_input":"2022-03-28T17:47:39.315149Z","iopub.status.idle":"2022-03-28T17:47:39.325411Z","shell.execute_reply.started":"2022-03-28T17:47:39.31511Z","shell.execute_reply":"2022-03-28T17:47:39.324742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T18:23:11.263528Z","iopub.execute_input":"2022-03-28T18:23:11.263810Z","iopub.status.idle":"2022-03-28T18:23:11.270657Z","shell.execute_reply.started":"2022-03-28T18:23:11.263779Z","shell.execute_reply":"2022-03-28T18:23:11.269214Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    lit = LitHurricane(train_paths,valid_paths,test_paths)\n    trainer = pl.Trainer(\n        max_epochs = 5,\n        gradient_clip_val=1,\n        progress_bar_refresh_rate = 0,\n        callbacks = [LitProgressBar()],\n        gpus = 1\n    )\n    trainer.fit(lit)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T18:23:13.082746Z","iopub.execute_input":"2022-03-28T18:23:13.083008Z","iopub.status.idle":"2022-03-28T18:25:02.881257Z","shell.execute_reply.started":"2022-03-28T18:23:13.082978Z","shell.execute_reply":"2022-03-28T18:25:02.880258Z"},"trusted":true},"execution_count":73,"outputs":[]}]}